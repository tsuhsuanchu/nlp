{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":127612,"sourceType":"datasetVersion","datasetId":64826}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/debbiechu/medical-transcriptions-nlp?scriptVersionId=174770820\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Purpose\n\nClassify transcriptions into correct medical specialties (imbalanced multiclass) using **transformer & NNs**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport torch\n\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"mtsamples.csv\")\nprint(df.shape)\ndf.head()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop rows where transcription is na\n\ndf = df.dropna(subset=['transcription'])\ndf.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.description[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.transcription[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use only the transcription because description info is included in the transcriptions.","metadata":{}},{"cell_type":"code","source":"df.medical_specialty.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of specialties\nlen(df.medical_specialty.unique())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform the classes to integers using factorization\n\ndf['medical_specialty_code'] = pd.factorize(df['medical_specialty'])[0]\ndf['medical_specialty_code'].head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.medical_specialty_code.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check balance in classes\ncounts = df.medical_specialty.value_counts()\n\nplt.figure(figsize=(20, 10)) \ncounts.plot(kind='bar', color='skyblue', edgecolor='black')\nplt.title('Medical Specialty Counts')\nplt.xlabel('Medical Specialty')\nplt.ylabel('Count')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Imbalanced. Will treat later.","metadata":{}},{"cell_type":"code","source":"df=df[['transcription','medical_specialty_code']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transcriptions Classification","metadata":{}},{"cell_type":"markdown","source":"### RoBERTa + Oversampling + MLP","metadata":{}},{"cell_type":"markdown","source":"Utilize `Roberta` to generate embeddings as features, `randomoversampler` for oversampling the minority classes, and `MLP` for the classification task.","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate embeddings","metadata":{}},{"cell_type":"code","source":"from transformers import RobertaModel, RobertaTokenizer\nimport torch\n\n# define X and y\nX = df['transcription'].tolist()\ny = df['medical_specialty_code'].tolist()\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nmodel = RobertaModel.from_pretrained('roberta-base').to(device)\n\n# Tokenize X\ninputs = tokenizer(X, padding=True, truncation=True, return_tensors=\"pt\", max_length=256)\n\n# generate embeddings in batches\ndef generate_embeddings(model, inputs, batch_size=16):\n    model.eval()\n    embeddings = []\n    for i in range(0, inputs['input_ids'].size(0), batch_size):\n        batch_input_ids = inputs['input_ids'][i:i+batch_size].to(device)\n        batch_attention_mask = inputs['attention_mask'][i:i+batch_size].to(device)\n        with torch.no_grad():\n            batch_outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n            batch_embeddings = batch_outputs.last_hidden_state.mean(dim=1)\n            embeddings.append(batch_embeddings.cpu().numpy())\n    embeddings = np.concatenate(embeddings, axis=0)\n    return embeddings\n\n# Generate embeddings\nembeddings = generate_embeddings(model, inputs, batch_size=16)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Oversampling","metadata":{}},{"cell_type":"code","source":"# apply oversampling\nfrom imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=42)\nembeddings_resampled, labels_resampled = ros.fit_resample(embeddings, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"classification","metadata":{}},{"cell_type":"code","source":"# train test val split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(embeddings_resampled, labels_resampled, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n\nfrom torch import nn, optim\nimport torch.nn.functional as F\n\n# MLP classifier\nclass SimpleClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_classes):\n        super(SimpleClassifier, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n# Initialize the classifier, loss criterion, and optimizer\nhidden_dim = 128\nnum_classes = 40\nmlp_model = SimpleClassifier(input_dim=768, hidden_dim=hidden_dim, num_classes=num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n\n# Prepare data loaders\nfrom torch.utils.data import DataLoader, TensorDataset\nbatch_size = 8\ntrain_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32).to(device), torch.tensor(y_train, dtype=torch.long).to(device))\nval_data = TensorDataset(torch.tensor(X_val, dtype=torch.float32).to(device), torch.tensor(y_val, dtype=torch.long).to(device))\ntrain_loader = DataLoader(train_data, batch_size=batch_size)\nval_loader = DataLoader(val_data, batch_size=batch_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nbest_val_loss = float('inf')\nbest_model_state = None\n\nepochs = 30\nfor epoch in range(epochs):\n    mlp_model.train()\n    train_loss = 0\n    for inputs, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = mlp_model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    train_loss /= len(train_loader)\n\n    # Validation for loss\n    mlp_model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            outputs = mlp_model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n    val_loss /= len(val_loader)\n\n    print(f'Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n\n    # Check if it's the lowest validation loss\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        best_model_state = mlp_model.state_dict() # Save the best model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the best model\ntorch.save(best_model_state, 'simple_classifier.pth')\n\n# Clear memory\ndel inputs, labels, outputs, train_data, val_data, train_loader, val_loader\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# initialize the loaded model\nloaded_model = SimpleClassifier(input_dim=768, hidden_dim=128, num_classes=40).to(device)\n\n# Load the saved model parameters\nloaded_model.load_state_dict(torch.load('simple_classifier.pth'))\n\n# Ensure the model is in evaluation mode\nloaded_model.eval()\n\n# Test dataset preparation\ntest_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32).to(device), torch.tensor(y_test, dtype=torch.long).to(device))\ntest_loader = DataLoader(test_data, batch_size=8)\n\n# Evaluate on the test set using the loaded model\ntest_preds, test_labels = [], []\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        outputs = loaded_model(inputs)\n        preds = torch.argmax(outputs, dim=1)\n        test_preds.extend(preds.cpu().numpy())\n        test_labels.extend(labels.cpu().numpy())\n\nprint(\"Classification Report on Test Set (Using Loaded Model):\")\nprint(classification_report(test_labels, test_preds))\nreport = classification_report(test_labels, test_preds, output_dict=True)\nmacro_avg_f1 = report['macro avg']['f1-score']\nweighted_avg_f1 = report['weighted avg']['f1-score']\nprint(f\"Macro Average F1 Score: {macro_avg_f1}\")\nprint(f\"Weighted Average F1 Score: {weighted_avg_f1}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RoBERTa + Oversampling + RF","metadata":{}},{"cell_type":"markdown","source":"Generate embeddings","metadata":{}},{"cell_type":"code","source":"from transformers import RobertaModel, RobertaTokenizer\nimport torch\n\n# define X and y\nX = df['transcription'].tolist()\ny = df['medical_specialty_code'].tolist()\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nmodel = RobertaModel.from_pretrained('roberta-base').to(device)\n\n# Tokenize X\ninputs = tokenizer(X, padding=True, truncation=True, return_tensors=\"pt\", max_length=256)\n\n# generate embeddings in batches\ndef generate_embeddings(model, inputs, batch_size=16):\n    model.eval()\n    embeddings = []\n    for i in range(0, inputs['input_ids'].size(0), batch_size):\n        batch_input_ids = inputs['input_ids'][i:i+batch_size].to(device)\n        batch_attention_mask = inputs['attention_mask'][i:i+batch_size].to(device)\n        with torch.no_grad():\n            batch_outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n            batch_embeddings = batch_outputs.last_hidden_state.mean(dim=1)\n            embeddings.append(batch_embeddings.cpu().numpy())\n    embeddings = np.concatenate(embeddings, axis=0)\n    return embeddings\n\n# Generate embeddings\nembeddings = generate_embeddings(model, inputs, batch_size=16)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Oversampling","metadata":{}},{"cell_type":"code","source":"# apply oversampling\nfrom imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=42)\nembeddings_resampled, labels_resampled = ros.fit_resample(embeddings, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Classification","metadata":{}},{"cell_type":"code","source":"from joblib import dump, load","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nimport numpy as np\nfrom sklearn.metrics import classification_report\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(embeddings_resampled, labels_resampled, test_size=0.2, random_state=42)\n\n# RF\nrf = RandomForestClassifier(random_state=42)\n\n# Param grid\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\n# Initialize and fit GridSearchCV\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='f1_weighted')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best parameters found: \", grid_search.best_params_)\nprint(\"Best weighted F1 score found: \", grid_search.best_score_)\n\ndump(grid_search, 'grid_search_rf.joblib')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# load the trained gridsearchcv object\ngrid_search = load('grid_search_rf.joblib')\n\n# Predicting on the test\ny_pred = grid_search.predict(X_test)\n\nprint(\"Classification Report on Test Set:\")\nprint(classification_report(y_test, y_pred))\nreport = classification_report(y_test, y_pred, output_dict=True)\nmacro_avg_f1 = report['macro avg']['f1-score']\nweighted_avg_f1 = report['weighted avg']['f1-score']\nprint(f\"Macro Average F1 Score: {macro_avg_f1}\")\nprint(f\"Weighted Average F1 Score: {weighted_avg_f1}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Slightly better than MLP","metadata":{}}]}